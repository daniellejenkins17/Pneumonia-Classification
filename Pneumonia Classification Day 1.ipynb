{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24364166",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/daniellejenkins17/Documents/GitHub/Pneumonia-Classification'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CNN is a form of deep learning that specializes in pattern recognition \n",
    "\n",
    "#ask Praveen to explain pooling for you "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4fdd72c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/daniellejenkins17/Documents/GitHub/Pneumonia-Classification'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ee3124d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np             \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d3f37daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "from random import randint\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c248724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # forlinear algebra\n",
    "import matplotlib.pyplot as plt #for plotting things\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "46b6c67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras Libraries\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5f18fa9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.layers import Dense # creates densely connected layer object\n",
    "from tensorflow.keras.layers import Flatten # takes 2D input and turns into 1D array\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D # convolution layer\n",
    "from tensorflow.keras.layers import MaxPooling2D # max pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b3a3f0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "41c13c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = \"data//train\"\n",
    "test_data_dir = \"data//test\"\n",
    "val_data_dir = \"data//val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ce18d5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 files belonging to 2 classes.\n",
      "Found 624 files belonging to 2 classes.\n",
      "Found 16 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "trn_data = image_dataset_from_directory(train_data_dir)\n",
    "tst_data = image_dataset_from_directory(test_data_dir)\n",
    "val_data = image_dataset_from_directory(val_data_dir)\n",
    "\n",
    "#the classes are pneumonia or no pneumonia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "71be7325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "(trn_data, train_data_dir), (tst_data, test_data_dir) = datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9c959902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "65cea98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ac4b307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = to_categorical(train_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f740ff90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conv2D takes tensors of shape:\n",
    "#(image_height, image_width, color_channels) for each image\n",
    "#MNIST has one color channel (grayscale)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cae47d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data = trn_data.reshape((60000, 28, 28, 1))\n",
    "tst_data = tst_data.reshape((10000, 28, 28, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0001e11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f360974",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next step is normalizing the data \n",
    "\n",
    "#scale at 255 \n",
    "\n",
    "#figure out what convolution vs pooling is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e1f71ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values to be between 0 and 1\n",
    "trn_data, tst_data = trn_data / 255, tst_data / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6b547a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# define 3x3 filter window sizes. Create 32 filters.\n",
    "model.add(Conv2D(filters=32,\n",
    "                        kernel_size=(3, 3),\n",
    "                        activation='relu',\n",
    "                        input_shape=(28, 28, 1)))\n",
    "# max pool in 2x2 window\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# define 3x3 filter window sizes. Create 64 filters.\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# transition to dense fully-connected part of network\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "16c3a898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "00971f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling and training the model\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8deefffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1500/1500 [==============================] - 22s 15ms/step - loss: 0.1676 - accuracy: 0.9486 - val_loss: 0.0718 - val_accuracy: 0.9787\n",
      "Epoch 2/20\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 0.0529 - accuracy: 0.9831 - val_loss: 0.0550 - val_accuracy: 0.9836\n",
      "Epoch 3/20\n",
      "1500/1500 [==============================] - 21s 14ms/step - loss: 0.0359 - accuracy: 0.9887 - val_loss: 0.0436 - val_accuracy: 0.9876\n",
      "Epoch 4/20\n",
      "1500/1500 [==============================] - 22s 15ms/step - loss: 0.0291 - accuracy: 0.9906 - val_loss: 0.0417 - val_accuracy: 0.9890\n",
      "Epoch 5/20\n",
      "1500/1500 [==============================] - 22s 15ms/step - loss: 0.0222 - accuracy: 0.9927 - val_loss: 0.0427 - val_accuracy: 0.9877\n",
      "Epoch 6/20\n",
      "1500/1500 [==============================] - 23s 16ms/step - loss: 0.0182 - accuracy: 0.9941 - val_loss: 0.0450 - val_accuracy: 0.9885\n",
      "Epoch 7/20\n",
      "1500/1500 [==============================] - 25s 17ms/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 0.0429 - val_accuracy: 0.9893\n",
      "Epoch 8/20\n",
      "1500/1500 [==============================] - 26s 17ms/step - loss: 0.0127 - accuracy: 0.9960 - val_loss: 0.0433 - val_accuracy: 0.9891\n",
      "Epoch 9/20\n",
      "1500/1500 [==============================] - 26s 18ms/step - loss: 0.0118 - accuracy: 0.9964 - val_loss: 0.0442 - val_accuracy: 0.9897\n",
      "Epoch 10/20\n",
      "1500/1500 [==============================] - 25s 17ms/step - loss: 0.0102 - accuracy: 0.9967 - val_loss: 0.0555 - val_accuracy: 0.9872\n",
      "Epoch 11/20\n",
      "1500/1500 [==============================] - 28s 19ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.0441 - val_accuracy: 0.9902\n",
      "Epoch 12/20\n",
      "1500/1500 [==============================] - 27s 18ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.0553 - val_accuracy: 0.9890\n",
      "Epoch 13/20\n",
      "1500/1500 [==============================] - 34s 23ms/step - loss: 0.0091 - accuracy: 0.9969 - val_loss: 0.0670 - val_accuracy: 0.9858\n",
      "Epoch 14/20\n",
      "1500/1500 [==============================] - 47s 31ms/step - loss: 0.0062 - accuracy: 0.9978 - val_loss: 0.0473 - val_accuracy: 0.9909\n",
      "Epoch 15/20\n",
      "1500/1500 [==============================] - 52s 35ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.0529 - val_accuracy: 0.9907\n",
      "Epoch 16/20\n",
      "1500/1500 [==============================] - 52s 35ms/step - loss: 0.0049 - accuracy: 0.9985 - val_loss: 0.0658 - val_accuracy: 0.9884\n",
      "Epoch 17/20\n",
      "1500/1500 [==============================] - 52s 35ms/step - loss: 0.0060 - accuracy: 0.9981 - val_loss: 0.0558 - val_accuracy: 0.9887\n",
      "Epoch 18/20\n",
      "1500/1500 [==============================] - 52s 35ms/step - loss: 0.0053 - accuracy: 0.9985 - val_loss: 0.0570 - val_accuracy: 0.9894\n",
      "Epoch 19/20\n",
      "1500/1500 [==============================] - 85s 57ms/step - loss: 0.0063 - accuracy: 0.9979 - val_loss: 0.0538 - val_accuracy: 0.9907\n",
      "Epoch 20/20\n",
      "1500/1500 [==============================] - 104s 69ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.0529 - val_accuracy: 0.9919\n"
     ]
    }
   ],
   "source": [
    "xrays = model.fit(trn_data, train_data_dir, epochs= 20, validation_split = 0.2, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "81d2eb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 20ms/step - loss: 0.0428 - accuracy: 0.9931\n"
     ]
    }
   ],
   "source": [
    "#evaluating the model\n",
    "\n",
    "_, test_acc = model.evaluate(tst_data, to_categorical(test_data_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "857d57d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#improving the model with regularization\n",
    "\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# a new layer that rescales/normalizes the activations after each layer.\n",
    "from tensorflow.keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "278d2a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "# define 3x3 filter window sizes. Create 32 filters.\n",
    "model2.add(Conv2D(filters=32,\n",
    "                        kernel_size=(3, 3),\n",
    "                        activation='relu',\n",
    "                        input_shape=(28, 28, 1), kernel_regularizer = l2(1e-2) ))\n",
    "\n",
    "model2.add(BatchNormalization())\n",
    "# max pool in 2x2 window\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# define 3x3 filter window sizes. Create 64 filters.\n",
    "model2.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer = l2(1e-2) ))\n",
    "\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "model2.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer = l2(1e-2)))\n",
    "\n",
    "model2.add(BatchNormalization())\n",
    "\n",
    "# transition to dense fully-connected part of network\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(64, activation='relu', kernel_regularizer = l2(1e-2)))\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "42212b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "750/750 [==============================] - 110s 147ms/step - loss: 0.8306 - accuracy: 0.9606 - val_loss: 0.2606 - val_accuracy: 0.9735\n",
      "Epoch 2/20\n",
      "750/750 [==============================] - 1173s 2s/step - loss: 0.2125 - accuracy: 0.9762 - val_loss: 0.2461 - val_accuracy: 0.9643\n",
      "Epoch 3/20\n",
      "750/750 [==============================] - 30s 41ms/step - loss: 0.1940 - accuracy: 0.9765 - val_loss: 0.2943 - val_accuracy: 0.9450\n",
      "Epoch 4/20\n",
      "750/750 [==============================] - 31s 42ms/step - loss: 0.1834 - accuracy: 0.9787 - val_loss: 0.2471 - val_accuracy: 0.9572\n",
      "Epoch 5/20\n",
      "750/750 [==============================] - 29s 39ms/step - loss: 0.1773 - accuracy: 0.9790 - val_loss: 0.1976 - val_accuracy: 0.9732\n",
      "Epoch 6/20\n",
      "750/750 [==============================] - 29s 39ms/step - loss: 0.1673 - accuracy: 0.9799 - val_loss: 0.1712 - val_accuracy: 0.9781\n",
      "Epoch 7/20\n",
      "750/750 [==============================] - 29s 39ms/step - loss: 0.1574 - accuracy: 0.9815 - val_loss: 0.1693 - val_accuracy: 0.9778\n",
      "Epoch 8/20\n",
      "750/750 [==============================] - 29s 39ms/step - loss: 0.1570 - accuracy: 0.9811 - val_loss: 0.1509 - val_accuracy: 0.9827\n",
      "Epoch 9/20\n",
      "750/750 [==============================] - 30s 40ms/step - loss: 0.1482 - accuracy: 0.9818 - val_loss: 0.1443 - val_accuracy: 0.9843\n",
      "Epoch 10/20\n",
      "750/750 [==============================] - 32s 43ms/step - loss: 0.1450 - accuracy: 0.9825 - val_loss: 0.1559 - val_accuracy: 0.9779\n",
      "Epoch 11/20\n",
      "750/750 [==============================] - 31s 41ms/step - loss: 0.1380 - accuracy: 0.9833 - val_loss: 0.1458 - val_accuracy: 0.9780\n",
      "Epoch 12/20\n",
      "750/750 [==============================] - 28s 37ms/step - loss: 0.1317 - accuracy: 0.9837 - val_loss: 0.1133 - val_accuracy: 0.9874\n",
      "Epoch 13/20\n",
      "750/750 [==============================] - 28s 37ms/step - loss: 0.1244 - accuracy: 0.9839 - val_loss: 0.1244 - val_accuracy: 0.9843\n",
      "Epoch 14/20\n",
      "750/750 [==============================] - 28s 37ms/step - loss: 0.1260 - accuracy: 0.9832 - val_loss: 0.1459 - val_accuracy: 0.9787\n",
      "Epoch 15/20\n",
      "750/750 [==============================] - 28s 37ms/step - loss: 0.1194 - accuracy: 0.9845 - val_loss: 0.1276 - val_accuracy: 0.9839\n",
      "Epoch 16/20\n",
      "750/750 [==============================] - 27s 37ms/step - loss: 0.1176 - accuracy: 0.9843 - val_loss: 0.1217 - val_accuracy: 0.9832\n",
      "Epoch 17/20\n",
      "750/750 [==============================] - 27s 37ms/step - loss: 0.1143 - accuracy: 0.9846 - val_loss: 0.1203 - val_accuracy: 0.9818\n",
      "Epoch 18/20\n",
      "750/750 [==============================] - 27s 37ms/step - loss: 0.1132 - accuracy: 0.9840 - val_loss: 0.1687 - val_accuracy: 0.9694\n",
      "Epoch 19/20\n",
      "750/750 [==============================] - 28s 37ms/step - loss: 0.1081 - accuracy: 0.9854 - val_loss: 0.1563 - val_accuracy: 0.9707\n",
      "Epoch 20/20\n",
      "750/750 [==============================] - 27s 37ms/step - loss: 0.1085 - accuracy: 0.9856 - val_loss: 0.1163 - val_accuracy: 0.9852\n"
     ]
    }
   ],
   "source": [
    "history_reg = model2.fit(trn_data, train_data_dir, epochs= 20, validation_split = 0.2, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f50156",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env]",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
